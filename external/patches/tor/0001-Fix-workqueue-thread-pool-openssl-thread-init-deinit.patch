From 558ebb501644fe9b85fc61e061977dc5f6e2e4be Mon Sep 17 00:00:00 2001
From: Matthew Nelson <developer@matthewnelson.io>
Date: Tue, 28 Oct 2025 09:25:36 -0400
Subject: [PATCH 1/2] Fix workqueue thread pool & openssl thread init/deinit
 issues Patch created from
 https://gitlab.torproject.org/tpo/core/tor/-/merge_requests/934

---
 src/lib/crypt_ops/crypto_init.c |  21 ++++
 src/lib/evloop/workqueue.c      | 171 ++++++++++++++++++++++----------
 src/lib/log/log.c               |  59 ++++++++++-
 src/lib/log/log.h               |  14 +++
 src/test/test_workqueue.c       |  26 ++++-
 5 files changed, 235 insertions(+), 56 deletions(-)

diff --git a/src/lib/crypt_ops/crypto_init.c b/src/lib/crypt_ops/crypto_init.c
index ef9908c893..340b16675f 100644
--- a/src/lib/crypt_ops/crypto_init.c
+++ b/src/lib/crypt_ops/crypto_init.c
@@ -22,6 +22,7 @@
 #include "lib/crypt_ops/crypto_openssl_mgt.h"
 #include "lib/crypt_ops/crypto_nss_mgt.h"
 #include "lib/crypt_ops/crypto_rand.h"
+#include "lib/crypt_ops/crypto_rsa.h"
 #include "lib/crypt_ops/crypto_sys.h"
 #include "lib/crypt_ops/crypto_options_st.h"
 #include "lib/conf/conftypes.h"
@@ -98,6 +99,26 @@ crypto_global_init(int useAccel, const char *accelName, const char *accelDir)
 #ifdef ENABLE_OPENSSL
     if (crypto_openssl_late_init(useAccel, accelName, accelDir) < 0)
       return -1;
+
+#if OPENSSL_VERSION_NUMBER >= 0x30000000L
+    /* OpenSSL 3.x: Pre-initialize crypto subsystems before creating worker
+     * threads. Without this, multiple threads performing RSA operations can
+     * trigger initialization races leading to NULL pointer crashes.
+     */
+    {
+      crypto_pk_t *warmup_key = crypto_pk_new();
+      if (warmup_key) {
+        if (crypto_pk_generate_key_with_bits(warmup_key, 512) == 0) {
+          unsigned char dummy_msg[20] = {0};
+          unsigned char dummy_sig[128];
+          crypto_pk_private_sign(warmup_key, (char*)dummy_sig,
+                                 sizeof(dummy_sig),
+                                 (char*)dummy_msg, sizeof(dummy_msg));
+        }
+        crypto_pk_free(warmup_key);
+      }
+    }
+#endif /* OPENSSL_VERSION_NUMBER >= 0x30000000L */
 #else
     (void)useAccel;
     (void)accelName;
diff --git a/src/lib/evloop/workqueue.c b/src/lib/evloop/workqueue.c
index f8a5cb87e9..e42b65ce3e 100644
--- a/src/lib/evloop/workqueue.c
+++ b/src/lib/evloop/workqueue.c
@@ -31,6 +31,13 @@
 #include "lib/evloop/workqueue.h"
 
 #include "lib/crypt_ops/crypto_rand.h"
+#include "lib/crypt_ops/crypto_init.h"
+#include "lib/crypt_ops/compat_openssl.h"
+
+#ifdef ENABLE_OPENSSL
+#include <openssl/crypto.h>
+#include <openssl/rand.h>
+#endif
 #include "lib/intmath/weakrng.h"
 #include "lib/log/ratelim.h"
 #include "lib/log/log.h"
@@ -43,7 +50,8 @@
 #include "ext/tor_queue.h"
 #include <event2/event.h>
 #include <string.h>
-
+#include <errno.h>
+#include <unistd.h>
 #define WORKQUEUE_PRIORITY_FIRST WQ_PRI_HIGH
 #define WORKQUEUE_PRIORITY_LAST WQ_PRI_LOW
 #define WORKQUEUE_N_PRIORITIES (((int) WORKQUEUE_PRIORITY_LAST)+1)
@@ -96,6 +104,10 @@ struct threadpool_t {
   int exit;
   /** Mutex for controlling worker threads' startup and exit. */
   tor_mutex_t control_lock;
+  /** Condition variable for main thread to wait for all workers to exit. */
+  tor_cond_t workers_finished;
+  /** Number of worker threads currently running. */
+  int n_workers_running;
 };
 
 /** Used to put a workqueue_priority_t value into a bitfield. */
@@ -278,20 +290,26 @@ worker_thread_extract_next_work(workerthread_t *thread)
 static void
 worker_thread_main(void *thread_)
 {
-  static int n_worker_threads_running = 0;
-  static unsigned long control_lock_owner = 0;
   workerthread_t *thread = thread_;
   threadpool_t *pool = thread->in_pool;
   workqueue_entry_t *work;
   workqueue_reply_t result;
 
+  /* Initialize thread-local crypto state for this worker thread.
+   * Each thread needs its own RNG state for Tor's crypto operations.
+   */
+  (void) get_thread_fast_rng();
+
   tor_mutex_acquire(&pool->control_lock);
+  pool->n_workers_running++;
   log_debug(LD_GENERAL, "Worker thread %u/%u has started [TID: %lu].",
-            n_worker_threads_running + 1, pool->n_threads_max,
+            pool->n_workers_running, pool->n_threads_max,
             tor_get_thread_id());
 
-  if (++n_worker_threads_running == pool->n_threads_max)
-    tor_cond_signal_one(&pool->condition);
+  /* Signal every time a worker starts. The main thread will check the count
+   * and decide whether all workers have started. This handles spurious
+   * wakeups correctly. */
+  tor_cond_signal_one(&pool->workers_finished);
 
   tor_mutex_release(&pool->control_lock);
 
@@ -299,13 +317,7 @@ worker_thread_main(void *thread_)
    * pool->lock must be prelocked here. */
   tor_mutex_acquire(&pool->lock);
 
-  if (control_lock_owner == 0) {
-    /* pool->control_lock stays locked. This is required for the main thread
-     * to wait for the worker threads to exit on shutdown, so the memory
-     * clean up won't begin before all threads have exited. */
-    tor_mutex_acquire(&pool->control_lock);
-    control_lock_owner = tor_get_thread_id();
-  }
+  /* Simplified synchronization: no need for control_lock ownership transfer */
 
   log_debug(LD_GENERAL, "Worker thread has entered the work loop [TID: %lu].",
             tor_get_thread_id());
@@ -366,28 +378,40 @@ worker_thread_main(void *thread_)
   }
 
 exit:
-  /* At this point pool->lock must be held */
+  /* Clean up thread-local crypto state before thread exit */
+  crypto_thread_cleanup();
 
-  log_debug(LD_GENERAL, "Worker thread %u/%u has exited [TID: %lu].",
-            pool->n_threads_max - n_worker_threads_running + 1,
-            pool->n_threads_max, tor_get_thread_id());
+#ifdef ENABLE_OPENSSL
+  /* Clean up OpenSSL thread-local state to prevent memory leaks */
+  OPENSSL_thread_stop();
+#endif
 
-  if (tor_get_thread_id() == control_lock_owner) {
-    /* Wait for the other worker threads to exit so we
-     * can safely unlock pool->control_lock. */
-    while (n_worker_threads_running > 1) {
-      tor_mutex_release(&pool->lock);
-      tor_sleep_msec(10);
-      tor_mutex_acquire(&pool->lock);
-    }
+  /* At this point pool->lock must be held - release before shutdown */
+  tor_mutex_release(&pool->lock);
 
-    tor_mutex_release(&pool->lock);
-    /* Let the main thread know, the last worker thread has exited. */
-    tor_mutex_release(&pool->control_lock);
-  } else {
-    --n_worker_threads_running;
-    tor_mutex_release(&pool->lock);
-  }
+  /* Notify main thread that a worker has exited.
+   *
+   * CRITICAL: We must signal on EVERY worker exit, not just the last one.
+   * Why? The main thread might start waiting between any two worker exits.
+   * If we only signal when n_workers_running hits 0, the main thread could
+   * miss the wakeup if it starts waiting after the last worker signals.
+   *
+   * Signaling on every exit ensures the main thread will be woken up and
+   * can recheck the count, even if it missed earlier signals.
+   */
+  tor_mutex_acquire(&pool->control_lock);
+  pool->n_workers_running--;
+
+  log_debug(LD_GENERAL, "Worker thread exited. %d/%u remaining [TID: %lu].",
+            pool->n_workers_running, pool->n_threads_max,
+            tor_get_thread_id());
+
+  /* Signal on every worker exit for reliability.
+   * The main thread will wake up, recheck n_workers_running, and either
+   * continue waiting or proceed with cleanup. */
+  tor_cond_signal_all(&pool->workers_finished);
+
+  tor_mutex_release(&pool->control_lock);
 }
 
 /** Put a reply on the reply queue.  The reply must not currently be on
@@ -579,7 +603,7 @@ threadpool_start_threads(threadpool_t *pool, int n)
   if (n > MAX_THREADS)
     n = MAX_THREADS;
 
-  tor_mutex_acquire(&pool->control_lock);
+  /* Acquire pool->lock to modify threads array and n_threads_max */
   tor_mutex_acquire(&pool->lock);
 
   if (pool->n_threads < n)
@@ -605,20 +629,33 @@ threadpool_start_threads(threadpool_t *pool, int n)
       tor_assert_nonfatal_unreached();
       pool->free_thread_state_fn(state);
       status = -1;
-      goto check_status;
+      tor_mutex_release(&pool->lock);
+      return status;
       //LCOV_EXCL_STOP
     }
     thr->index = pool->n_threads;
     pool->threads[pool->n_threads++] = thr;
   }
 
+  /* Release pool->lock before acquiring control_lock to maintain consistent
+   * lock ordering: never hold both locks simultaneously. */
+  tor_mutex_release(&pool->lock);
+
+  /* Now wait for threads to start using control_lock */
+  tor_mutex_acquire(&pool->control_lock);
+
   struct timeval tv = {.tv_sec = 30, .tv_usec = 0};
 
-  /* Wait for the last launched thread to confirm us, it has started.
-   * Wait max 30 seconds */
-  status = tor_cond_wait(&pool->condition, &pool->control_lock, &tv);
+  /* Wait for all workers to start. Loop handles spurious wakeups.
+   * Similar to shutdown logic: simple, clean, based on count alone. */
+  while (pool->n_workers_running < pool->n_threads_max) {
+    status = tor_cond_wait(&pool->workers_finished, &pool->control_lock, &tv);
+    if (status != 0) {
+      /* Timeout or error */
+      break;
+    }
+  }
 
-check_status:
   switch (status) {
   case 0:
     log_debug(LD_GENERAL, "Starting worker threads finished.");
@@ -636,18 +673,19 @@ check_status:
 
   log_debug(LD_GENERAL, "Signaled the worker threads to enter the work loop.");
 
-  /* If we had an error, let the worker threads (if any) exit directly. */
+  /* If we had an error, signal worker threads to exit */
   if (status != 0) {
+    /* Need pool->lock to set exit flag */
+    tor_mutex_release(&pool->control_lock);
+    tor_mutex_acquire(&pool->lock);
     pool->exit = 1;
+    tor_cond_signal_all(&pool->condition);
+    tor_mutex_release(&pool->lock);
     log_debug(LD_GENERAL, "Signaled the worker threads to exit...");
+  } else {
+    tor_mutex_release(&pool->control_lock);
   }
 
-  /* Let worker threads enter the work loop. */
-  tor_mutex_release(&pool->lock);
-  /* Let one of the worker threads take the ownership of pool->control_lock.
-   * This is required for compliance with POSIX. */
-  tor_mutex_release(&pool->control_lock);
-
   return status;
 }
 
@@ -670,13 +708,18 @@ threadpool_stop_threads(threadpool_t *pool)
   tor_mutex_release(&pool->lock);
 
   /* Wait until all worker threads have exited.
-   * pool->control_lock must be prelocked here. */
+   * Each worker decrements n_workers_running and signals the condition
+   * variable before exiting. */
   tor_mutex_acquire(&pool->control_lock);
-  /* Unlock required, else main thread hangs on mutex uninit. */
+
+  while (pool->n_workers_running > 0) {
+    log_debug(LD_GENERAL, "Waiting for %d worker threads to exit...",
+              pool->n_workers_running);
+    tor_cond_wait(&pool->workers_finished, &pool->control_lock, NULL);
+  }
+
   tor_mutex_release(&pool->control_lock);
 
-  /* If this message appears in the log before all threads have confirmed
-   * their exit, then pool->control_lock wasn't prelocked for some reason. */
   log_debug(LD_GENERAL, "All worker threads have exited.");
 }
 
@@ -699,7 +742,9 @@ threadpool_new(int n_threads,
   tor_mutex_init_nonrecursive(&pool->lock);
   tor_cond_init(&pool->condition);
   tor_mutex_init_nonrecursive(&pool->control_lock);
+  tor_cond_init(&pool->workers_finished);
   pool->exit = 0;
+  pool->n_workers_running = 0;
 
   unsigned i;
   for (i = WORKQUEUE_PRIORITY_FIRST; i <= WORKQUEUE_PRIORITY_LAST; ++i) {
@@ -736,6 +781,7 @@ threadpool_free_(threadpool_t *pool)
   log_debug(LD_GENERAL, "Beginning to clean up...");
 
   tor_cond_uninit(&pool->condition);
+  tor_cond_uninit(&pool->workers_finished);
   tor_mutex_uninit(&pool->lock);
   tor_mutex_uninit(&pool->control_lock);
 
@@ -747,11 +793,32 @@ threadpool_free_(threadpool_t *pool)
   }
 
   if (pool->update_args) {
-    if (!pool->free_update_arg_fn)
+    if (!pool->free_update_arg_fn) {
       log_warn(LD_GENERAL, "Freeing pool->update_args not possible. "
                            "pool->free_update_arg_fn is not set.");
-    else
-      pool->free_update_arg_fn(pool->update_args);
+    } else {
+      /* Free each individual update argument */
+      for (int i = 0; i < pool->n_threads; ++i) {
+        if (pool->update_args[i])
+          pool->free_update_arg_fn(pool->update_args[i]);
+      }
+    }
+    /* Free the update_args array itself */
+    tor_free(pool->update_args);
+  }
+
+  /* Free any pending work items that were never processed.
+   * This can happen when the pool is shut down while work is still queued,
+   * such as during rapid shutdown or when reply callbacks queue more work
+   * during cleanup. */
+  for (unsigned i = WORKQUEUE_PRIORITY_FIRST;
+       i <= WORKQUEUE_PRIORITY_LAST; ++i) {
+    workqueue_entry_t *work;
+    while (!TOR_TAILQ_EMPTY(&pool->work[i])) {
+      work = TOR_TAILQ_FIRST(&pool->work[i]);
+      TOR_TAILQ_REMOVE(&pool->work[i], work, next_work);
+      workqueue_entry_free(work);
+    }
   }
 
   if (pool->reply_event) {
diff --git a/src/lib/log/log.c b/src/lib/log/log.c
index db57ee61a2..854d7891da 100644
--- a/src/lib/log/log.c
+++ b/src/lib/log/log.c
@@ -183,8 +183,15 @@ static int pretty_fn_has_parens = 0;
   STMT_END
 
 /** What's the lowest log level anybody cares about?  Checking this lets us
- * bail out early from log_debug if we aren't debugging.  */
+ * bail out early from log_debug if we aren't debugging.
+ * This is an atomic variable to ensure thread-safe access from worker threads
+ * without requiring the log_mutex lock for frequent read operations.
+ * The atomic version is initialized in init_logging(). */
+#ifdef HAVE_WORKING_STDATOMIC
+atomic_int log_global_min_severity_;
+#else
 int log_global_min_severity_ = LOG_NOTICE;
+#endif
 
 static void delete_log(logfile_t *victim);
 static void close_log(logfile_t *victim);
@@ -222,7 +229,11 @@ int
 log_message_is_interesting(int severity, log_domain_mask_t domain)
 {
   (void) domain;
+#ifdef HAVE_WORKING_STDATOMIC
+  return (severity <= atomic_load(&log_global_min_severity_));
+#else
   return (severity <= log_global_min_severity_);
+#endif
 }
 
 /**
@@ -594,8 +605,13 @@ tor_log(int severity, log_domain_mask_t domain, const char *format, ...)
   /* check that domain is composed of known domains and flags */
   raw_assert((domain & (LD_ALL_DOMAINS|LD_ALL_FLAGS)) == domain);
 
+#ifdef HAVE_WORKING_STDATOMIC
+  if (severity > atomic_load(&log_global_min_severity_))
+    return;
+#else
   if (severity > log_global_min_severity_)
     return;
+#endif
   va_start(ap,format);
 #ifdef TOR_UNIT_TESTS
   if (domain & LD_NO_MOCK)
@@ -706,8 +722,13 @@ log_fn_(int severity, log_domain_mask_t domain, const char *fn,
         const char *format, ...)
 {
   va_list ap;
+#ifdef HAVE_WORKING_STDATOMIC
+  if (severity > atomic_load(&log_global_min_severity_))
+    return;
+#else
   if (severity > log_global_min_severity_)
     return;
+#endif
   va_start(ap,format);
   logv(severity, domain, fn, NULL, format, ap);
   va_end(ap);
@@ -718,8 +739,13 @@ log_fn_ratelim_(ratelim_t *ratelim, int severity, log_domain_mask_t domain,
 {
   va_list ap;
   char *m;
+#ifdef HAVE_WORKING_STDATOMIC
+  if (severity > atomic_load(&log_global_min_severity_))
+    return;
+#else
   if (severity > log_global_min_severity_)
     return;
+#endif
   m = rate_limit_log(ratelim, approx_time());
   if (m == NULL)
       return;
@@ -892,7 +918,11 @@ add_stream_log_impl,(const log_severity_list_t *severity,
   lf->next = logfiles;
 
   logfiles = lf;
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
 }
 
 /** Add a log handler named <b>name</b> to send all messages in <b>severity</b>
@@ -914,6 +944,9 @@ init_logging(int disable_startup_queue)
     tor_mutex_init(&log_mutex);
     log_mutex_initialized = 1;
   }
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_init(&log_global_min_severity_, LOG_NOTICE);
+#endif
 #ifdef __GNUC__
   if (strchr(__PRETTY_FUNCTION__, '(')) {
     pretty_fn_has_parens = 1;
@@ -986,7 +1019,11 @@ add_callback_log(const log_severity_list_t *severity, log_callback cb)
 
   LOCK_LOGS();
   logfiles = lf;
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
   UNLOCK_LOGS();
   return 0;
 }
@@ -1006,7 +1043,11 @@ change_callback_log_severity(int loglevelMin, int loglevelMax,
       memcpy(lf->severities, &severities, sizeof(severities));
     }
   }
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
   UNLOCK_LOGS();
 }
 
@@ -1109,7 +1150,11 @@ close_temp_logs(void)
     }
   }
 
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
   UNLOCK_LOGS();
 }
 
@@ -1160,7 +1205,11 @@ add_file_log,(const log_severity_list_t *severity,
   add_stream_log_impl(severity, filename, fd);
   logfiles->needs_close = 1;
   lf = logfiles;
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
 
   if (log_tor_version(lf, 0) < 0) {
     delete_log(lf);
@@ -1202,7 +1251,11 @@ add_syslog_log(const log_severity_list_t *severity,
   LOCK_LOGS();
   lf->next = logfiles;
   logfiles = lf;
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
   UNLOCK_LOGS();
   return 0;
 }
@@ -1447,7 +1500,11 @@ switch_logs_debug(void)
     for (i = LOG_DEBUG; i >= LOG_ERR; --i)
       lf->severities->masks[SEVERITY_MASK_IDX(i)] = LD_ALL_DOMAINS;
   }
+#ifdef HAVE_WORKING_STDATOMIC
+  atomic_store(&log_global_min_severity_, get_min_log_level());
+#else
   log_global_min_severity_ = get_min_log_level();
+#endif
   UNLOCK_LOGS();
 }
 
diff --git a/src/lib/log/log.h b/src/lib/log/log.h
index f624309d82..18167a9c27 100644
--- a/src/lib/log/log.h
+++ b/src/lib/log/log.h
@@ -19,6 +19,9 @@
 #include "lib/defs/logging_types.h"
 #include "lib/testsupport/testsupport.h"
 
+/* For atomic operations on log_global_min_severity_ */
+#include "lib/thread/threads.h"
+
 #ifdef HAVE_SYSLOG_H
 #include <syslog.h>
 #define LOG_WARN LOG_WARNING
@@ -203,7 +206,14 @@ void tor_log_update_sigsafe_err_fds(void);
 struct smartlist_t;
 void tor_log_get_logfile_names(struct smartlist_t *out);
 
+/* Atomic variable to track the lowest log level anybody cares about.
+ * We use atomic operations to ensure thread-safe access without needing
+ * to acquire the log_mutex for the frequent read operations. */
+#ifdef HAVE_WORKING_STDATOMIC
+extern atomic_int log_global_min_severity_;
+#else
 extern int log_global_min_severity_;
+#endif
 
 #ifdef TOR_COVERAGE
 /* For coverage builds, we try to avoid our log_debug optimization, since it
@@ -216,7 +226,11 @@ static inline bool debug_logging_enabled(void);
  */
 static inline bool debug_logging_enabled(void)
 {
+#ifdef HAVE_WORKING_STDATOMIC
+  return PREDICT_UNLIKELY(atomic_load(&log_global_min_severity_) == LOG_DEBUG);
+#else
   return PREDICT_UNLIKELY(log_global_min_severity_ == LOG_DEBUG);
+#endif
 }
 #endif /* defined(TOR_COVERAGE) */
 
diff --git a/src/test/test_workqueue.c b/src/test/test_workqueue.c
index 19f8934f3c..9625732f59 100644
--- a/src/test/test_workqueue.c
+++ b/src/test/test_workqueue.c
@@ -426,10 +426,13 @@ main(int argc, char **argv)
   handled_len = opt_n_items;
 #endif /* defined(TRACK_RESPONSES) */
 
+  int test_result = 0;
+
   for (i = 0; i < opt_n_inflight; ++i) {
     if (! add_work(tp)) {
       puts("Couldn't add work.");
-      return 1;
+      test_result = 1;
+      goto cleanup;
     }
   }
 
@@ -444,12 +447,29 @@ main(int argc, char **argv)
     printf("%d vs %d\n", n_sent, opt_n_items);
     printf("%d+%d vs %d\n", n_received, n_successful_cancel, n_sent);
     puts("FAIL");
-    return 1;
+    test_result = 1;
   } else if (no_shutdown) {
     puts("Accepted work after shutdown\n");
     puts("FAIL");
+    test_result = 1;
   } else {
     puts("OK");
-    return 0;
+    test_result = 0;
+  }
+
+cleanup:
+  /* CRITICAL: Always cleanup threadpool to avoid races with atexit handlers.
+   * Without this, workers may still be running when exit() calls
+   * OPENSSL_cleanup(), causing data races on OpenSSL globals. */
+  if (tp) {
+    threadpool_free(tp);
   }
+
+#ifdef TRACK_RESPONSES
+  bitarray_free(handled);
+  bitarray_free(received);
+  tor_mutex_uninit(&bitmap_mutex);
+#endif
+
+  return test_result;
 }
-- 
2.34.1

